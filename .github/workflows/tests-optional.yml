name: Optional Tests

on:
  workflow_dispatch:
    inputs:
      test_category:
        description: 'Test category to run'
        required: true
        default: 'all'
        type: choice
        options:
          - 'all'                    # All slow tests
          - 'e2e'                   # E2E tests only
          - 'performance'           # Performance tests only
          - 'accessibility'         # Accessibility tests only
          - 'visual'               # Visual regression tests only
          - 'pre-release'          # Critical tests for releases
      browser_matrix:
        description: 'Browser matrix (for E2E tests)'
        required: false
        default: 'chromium'
        type: choice
        options:
          - 'chromium'             # Chromium only (fast)
          - 'all'                  # All browsers (slow)
      environment:
        description: 'Environment to test'
        required: false
        default: 'production'
        type: choice
        options:
          - 'production'
          - 'staging'
          - 'local'

env:
  NODE_VERSION: '20'
  TEST_CATEGORY: ${{ inputs.test_category || 'all' }}
  BROWSER_MATRIX: ${{ inputs.browser_matrix || 'chromium' }}
  TEST_ENVIRONMENT: ${{ inputs.environment || 'production' }}

jobs:
  # Determine test strategy
  determine-tests:
    runs-on: ubuntu-latest
    outputs:
      run-e2e: ${{ steps.strategy.outputs.run-e2e }}
      run-performance: ${{ steps.strategy.outputs.run-performance }}
      run-accessibility: ${{ steps.strategy.outputs.run-accessibility }}
      run-visual: ${{ steps.strategy.outputs.run-visual }}
      browsers: ${{ steps.strategy.outputs.browsers }}
      description: ${{ steps.strategy.outputs.description }}
      
    steps:
      - name: Determine test strategy
        id: strategy
        run: |
          echo "Determining test strategy for: ${{ env.TEST_CATEGORY }}"
          
          # Default values
          RUN_E2E=false
          RUN_PERFORMANCE=false
          RUN_ACCESSIBILITY=false
          RUN_VISUAL=false
          DESCRIPTION=""
          
          # Browser configuration
          if [ "${{ env.BROWSER_MATRIX }}" = "all" ]; then
            BROWSERS='["chromium", "firefox", "webkit"]'
          else
            BROWSERS='["chromium"]'
          fi
          
          # Set tests based on category
          case "${{ env.TEST_CATEGORY }}" in
            "all")
              RUN_E2E=true
              RUN_PERFORMANCE=true
              RUN_ACCESSIBILITY=true
              RUN_VISUAL=true
              DESCRIPTION="Complete comprehensive test suite"
              ;;
            "e2e")
              RUN_E2E=true
              DESCRIPTION="End-to-end testing across browsers"
              ;;
            "performance")
              RUN_PERFORMANCE=true
              DESCRIPTION="Performance and Lighthouse audits"
              ;;
            "accessibility")
              RUN_ACCESSIBILITY=true
              DESCRIPTION="Accessibility compliance testing"
              ;;
            "visual")
              RUN_VISUAL=true
              DESCRIPTION="Visual regression testing"
              ;;
            "pre-release")
              RUN_E2E=true
              RUN_PERFORMANCE=true
              BROWSERS='["chromium"]'  # Fast pre-release check
              DESCRIPTION="Pre-release validation (E2E + Performance)"
              ;;
          esac
          
          echo "run-e2e=$RUN_E2E" >> $GITHUB_OUTPUT
          echo "run-performance=$RUN_PERFORMANCE" >> $GITHUB_OUTPUT
          echo "run-accessibility=$RUN_ACCESSIBILITY" >> $GITHUB_OUTPUT
          echo "run-visual=$RUN_VISUAL" >> $GITHUB_OUTPUT
          echo "browsers=$BROWSERS" >> $GITHUB_OUTPUT
          echo "description=$DESCRIPTION" >> $GITHUB_OUTPUT
          
          echo "Test Strategy:"
          echo "- E2E: $RUN_E2E"
          echo "- Performance: $RUN_PERFORMANCE"
          echo "- Accessibility: $RUN_ACCESSIBILITY"
          echo "- Visual: $RUN_VISUAL"
          echo "- Browsers: $BROWSERS"
          echo "- Description: $DESCRIPTION"

  # E2E Tests
  e2e-tests:
    needs: determine-tests
    if: needs.determine-tests.outputs.run-e2e == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        browser: ${{ fromJSON(needs.determine-tests.outputs.browsers) }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npx playwright install ${{ matrix.browser }} --with-deps

      - name: Build application
        run: npm run build

      - name: Start development server
        run: npm run preview &
        
      - name: Wait for server
        run: |
          timeout 60 bash -c 'until curl -s http://localhost:4173 > /dev/null; do sleep 1; done'

      - name: Run E2E tests
        run: npx playwright test --config ./configs/playwright.config.ts --project=${{ matrix.browser }}
        env:
          CI: true
          BASE_URL: http://localhost:4173

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-results-${{ matrix.browser }}
          path: |
            test-results/
            playwright-report/
          retention-days: 7

  # Performance Tests
  performance-tests:
    needs: determine-tests
    if: needs.determine-tests.outputs.run-performance == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npx playwright install chromium --with-deps

      - name: Build application
        run: npm run build

      - name: Run performance tests
        run: npm run test:performance
        timeout-minutes: 15
        env:
          CI: true

      - name: Run Lighthouse audit
        run: |
          npm run preview &
          sleep 5
          timeout 300 npm run lighthouse:ci || echo "Lighthouse completed with warnings"

      - name: Upload performance reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports
          path: |
            test-results/reports/
            lighthouse-reports/
          retention-days: 14

  # Accessibility Tests  
  accessibility-tests:
    needs: determine-tests
    if: needs.determine-tests.outputs.run-accessibility == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npx playwright install chromium --with-deps

      - name: Build application
        run: npm run build

      - name: Run accessibility tests
        run: npm run test:a11y:audit
        timeout-minutes: 10
        env:
          CI: true

      - name: Upload accessibility reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: accessibility-reports
          path: |
            test-results/
            coverage/
          retention-days: 7

  # Visual Regression Tests
  visual-tests:
    needs: determine-tests
    if: needs.determine-tests.outputs.run-visual == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npx playwright install chromium --with-deps

      - name: Build application
        run: npm run build

      - name: Start development server
        run: npm run preview &
        
      - name: Wait for server
        run: |
          timeout 60 bash -c 'until curl -s http://localhost:4173 > /dev/null; do sleep 1; done'

      - name: Run visual tests
        run: npm run test:visual:chromium
        env:
          CI: true
          BASE_URL: http://localhost:4173

      - name: Upload visual test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: visual-test-results
          path: |
            test-results/
            visual-tests/
          retention-days: 14

  # Test Summary
  test-summary:
    runs-on: ubuntu-latest
    needs: [determine-tests, e2e-tests, performance-tests, accessibility-tests, visual-tests]
    if: always()
    
    steps:
      - name: Generate test summary
        run: |
          echo "## Optional Tests Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Category**: ${{ env.TEST_CATEGORY }}" >> $GITHUB_STEP_SUMMARY
          echo "**Description**: ${{ needs.determine-tests.outputs.description }}" >> $GITHUB_STEP_SUMMARY
          echo "**Environment**: ${{ env.TEST_ENVIRONMENT }}" >> $GITHUB_STEP_SUMMARY
          echo "**Browsers**: ${{ env.BROWSER_MATRIX }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test results
          E2E_STATUS="${{ needs.e2e-tests.result }}"
          PERF_STATUS="${{ needs.performance-tests.result }}"
          A11Y_STATUS="${{ needs.accessibility-tests.result }}"
          VISUAL_STATUS="${{ needs.visual-tests.result }}"
          
          echo "### Test Results" >> $GITHUB_STEP_SUMMARY
          
          if [ "$E2E_STATUS" != "skipped" ]; then
            if [ "$E2E_STATUS" = "success" ]; then
              echo "- 🌐 **E2E Tests**: ✅ Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- 🌐 **E2E Tests**: ❌ Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "$PERF_STATUS" != "skipped" ]; then
            if [ "$PERF_STATUS" = "success" ]; then
              echo "- ⚡ **Performance Tests**: ✅ Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ⚡ **Performance Tests**: ❌ Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "$A11Y_STATUS" != "skipped" ]; then
            if [ "$A11Y_STATUS" = "success" ]; then
              echo "- ♿ **Accessibility Tests**: ✅ Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ♿ **Accessibility Tests**: ❌ Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "$VISUAL_STATUS" != "skipped" ]; then
            if [ "$VISUAL_STATUS" = "success" ]; then
              echo "- 👁️ **Visual Tests**: ✅ Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- 👁️ **Visual Tests**: ❌ Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "💡 **Note**: These tests are optional and don't block merging" >> $GITHUB_STEP_SUMMARY
          echo "📊 **Artifacts**: Test reports are available in the workflow artifacts" >> $GITHUB_STEP_SUMMARY